{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_WF4iWrT-HqO",
        "BJC0AWcedvxa"
      ],
      "authorship_tag": "ABX9TyNNfz3EsDe8yBVMQ65QEcV8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andresbadillo/aenc_tfroc/blob/master/aenc_tfroc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Consumo = aenc / Factor de pérdidas del `-día-`\n",
        "\n",
        "En este pieza se código se cargan los archivos aenc y tfroc del mismo día seleccionado y se realiza la división de cada valor horario por el factor de perdidas"
      ],
      "metadata": {
        "id": "_WF4iWrT-HqO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "to3EiQTEyooS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar los archivos desde Google Colab\n",
        "from google.colab import files\n",
        "\n",
        "# Subir los archivos\n",
        "print(\"Por favor, sube el archivo aenc\")\n",
        "aenc_file = files.upload()\n",
        "\n",
        "print(\"\\nPor favor, sube el archivo tfroc\")\n",
        "tfroc_file = files.upload()\n",
        "\n",
        "# Leer los archivos con el separador \";\"\n",
        "aenc_file_path = list(aenc_file.keys())[0]\n",
        "tfroc_file_path = list(tfroc_file.keys())[0]\n",
        "\n",
        "aenc_df = pd.read_csv(aenc_file_path, sep=\";\", encoding='latin1')\n",
        "tfroc_df = pd.read_csv(tfroc_file_path, sep=\";\", encoding='latin1')\n",
        "\n",
        "# Renombrar columnas para facilitar la unión\n",
        "aenc_df.rename(columns={\"CODIGO SIC\": \"CODIGO FRONTERA\"}, inplace=True)\n",
        "\n",
        "# Unir los dos dataframes utilizando \"CODIGO FRONTERA\"\n",
        "merged_df = pd.merge(aenc_df, tfroc_df[[\"CODIGO FRONTERA\", \"FACTOR DE PERDIDAS\"]], on=\"CODIGO FRONTERA\", how=\"inner\")\n",
        "\n",
        "# Dividir los valores de aenc horario por el FACTOR DE PERDIDAS\n",
        "horas = [col for col in aenc_df.columns if \"HORA\" in col]\n",
        "for hora in horas:\n",
        "    merged_df[hora] = merged_df[hora] / merged_df[\"FACTOR DE PERDIDAS\"]\n",
        "\n",
        "# Agregar columnas adicionales al archivo de salida\n",
        "merged_df.rename(columns={\"CODIGO PROPIO\": \"NOMBRE FRONTERA\"}, inplace=True)\n",
        "output_df = merged_df[[\"CODIGO FRONTERA\", \"NOMBRE FRONTERA\", \"TIPO DE AGRUPACIÓN\", \"IMPO - EXPO\"] + horas]\n",
        "\n",
        "# Agregar columna de total de consumo por frontera\n",
        "output_df[\"TOTAL CONSUMO\"] = output_df[horas].sum(axis=1)\n",
        "\n",
        "# Exportar a un archivo CSV\n",
        "output_file_name = \"consumos_1201.csv\"\n",
        "output_df.to_csv(output_file_name, index=False, sep=\";\")\n",
        "\n",
        "# Descargar el archivo resultante\n",
        "files.download(output_file_name)\n",
        "print(f\"\\nEl archivo {output_file_name} ha sido descargado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Consumo = aenc / Factor de pérdidas del `-Mes-`\n",
        "\n",
        "En este pieza se código se cargan los archivos aenc y tfroc del mismo mes y se realiza la división de cada valor horario por el factor de perdidas. Hay dos archivos exportados:\n",
        "- Archivo que consolida todos los aenc del mes: aenc_consolidado_`{mm}`_`{aaaa}`.csv\n",
        "- Archivo que consolida los consumos del mes: consumos_`{mm}`_`{aaaa}`.csv"
      ],
      "metadata": {
        "id": "_USsogaE-1yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install holidays_co\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "import holidays_co\n",
        "\n",
        "# Configurar el año\n",
        "anio_actual = 2025  # Cambiar este valor según sea necesario\n",
        "\n",
        "# Cargar los archivos desde Google Colab\n",
        "from google.colab import files\n",
        "\n",
        "# Subir los archivos\n",
        "aenc_files = []\n",
        "tfroc_files = []\n",
        "\n",
        "print(\"Por favor, sube todos los archivos de 'aenc' del mes\")\n",
        "aenc_uploaded = files.upload()\n",
        "aenc_files.extend(aenc_uploaded.keys())\n",
        "\n",
        "print(\"\\nPor favor, sube todos los archivos de 'tfroc' del mes\")\n",
        "tfroc_uploaded = files.upload()\n",
        "tfroc_files.extend(tfroc_uploaded.keys())\n",
        "\n",
        "# Inicializar dataframes vacíos para consolidar los resultados\n",
        "consolidated_aenc_df = pd.DataFrame()\n",
        "consolidated_df = pd.DataFrame()\n",
        "\n",
        "# Función para obtener el nombre del día en español\n",
        "def obtener_dia_semana(fecha):\n",
        "    dias_semana = [\"Lunes\", \"Martes\", \"Miércoles\", \"Jueves\", \"Viernes\", \"Sábado\", \"Domingo\"]\n",
        "    dia_semana = datetime.strptime(fecha, \"%d-%m-%Y\").weekday()\n",
        "    return dias_semana[dia_semana]\n",
        "\n",
        "# Obtener los festivos de Colombia para el año configurado\n",
        "festivos = holidays_co.get_colombia_holidays_by_year(anio_actual)\n",
        "#print(f\"Festivos del año {anio_actual}: {festivos}\")\n",
        "\n",
        "# Función para determinar el tipo de día\n",
        "def tipo_dia(fecha):\n",
        "    fecha_obj = datetime.strptime(fecha, \"%d-%m-%Y\").date()\n",
        "\n",
        "    if holidays_co.is_holiday_date(fecha_obj):  # Verificar si es festivo\n",
        "        return \"Festivo\"\n",
        "\n",
        "    # Si no es festivo, determinar si es lunes a viernes, sábado o domingo\n",
        "    dia_semana = fecha_obj.weekday()  # 0: Lunes, 1: Martes, ..., 6: Domingo\n",
        "    if dia_semana == 5:  # Sábado\n",
        "        return \"Sábado\"\n",
        "    elif dia_semana == 6:  # Domingo\n",
        "        return \"Domingo\"\n",
        "    else:  # Lunes a Viernes\n",
        "        return \"Hábil\"\n",
        "\n",
        "# Diccionario de mapeo para la columna \"OR\"\n",
        "mapeo_or = {\n",
        "    \"CUNM\": \"ENEL\",\n",
        "    \"SOLM\": \"AIRE\",\n",
        "    \"SANM\": \"ESSA\",\n",
        "    \"MARM\": \"AFINIA\",\n",
        "    \"NSAM\": \"ESSA\",\n",
        "    \"BOYM\": \"EBSA\",\n",
        "    \"CASM\": \"ENERCA\",\n",
        "    \"METM\": \"EMSA\",\n",
        "    \"QUIM\": \"EDEQ\",\n",
        "    \"RUIM\": \"RUITOQUE\",\n",
        "    \"CHOM\": \"DISPAC\",\n",
        "    \"CLOM\": \"EMCALI\"\n",
        "}\n",
        "\n",
        "# Función para mapear el NT por rangos\n",
        "def mapear_nt_por_rango(valor):\n",
        "    if valor in {1, 2}:  # Comprobamos si el valor es exactamente 1 o 2\n",
        "        return valor\n",
        "    elif valor < 1:\n",
        "        return 1\n",
        "    elif valor < 30:\n",
        "        return 2\n",
        "    elif valor < 57.5:\n",
        "        return 3\n",
        "    return None  # O un valor por defecto si no encaja en ningún rango\n",
        "\n",
        "# Procesar archivos día a día\n",
        "for aenc_file_path in aenc_files:\n",
        "    # Extraer el día y el mes del nombre del archivo\n",
        "    day = os.path.splitext(aenc_file_path)[0][-4:]  # Los últimos 4 caracteres son el día\n",
        "    date = f\"{day[2:]}-{day[:2]}-{anio_actual}\"  # Formatear como dd-mm-aaaa\n",
        "\n",
        "    # Buscar el archivo tfroc correspondiente\n",
        "    tfroc_file_path = next((f for f in tfroc_files if day in f), None)\n",
        "    if tfroc_file_path is None:\n",
        "        print(f\"No se encontró un archivo tfroc correspondiente para el día {day}.\")\n",
        "        continue\n",
        "\n",
        "    # Leer los archivos con el separador \";\"\n",
        "    aenc_df = pd.read_csv(aenc_file_path, sep=\";\", encoding='latin1')\n",
        "    tfroc_df = pd.read_csv(tfroc_file_path, sep=\";\", encoding='latin1')\n",
        "\n",
        "    # Renombrar columnas para facilitar la unión\n",
        "    aenc_df.rename(columns={\"CODIGO SIC\": \"CODIGO FRONTERA\"}, inplace=True)\n",
        "\n",
        "    # Agregar columnas adicionales al dataframe de aenc\n",
        "    horas = [col for col in aenc_df.columns if \"HORA\" in col]\n",
        "    aenc_df.insert(0, \"FECHA\", date)\n",
        "    aenc_df.insert(1, \"DIA\", obtener_dia_semana(date))\n",
        "    aenc_df.insert(2, \"TIPO_DIA\", tipo_dia(date))\n",
        "    aenc_df[\"TOTAL CONSUMO\"] = aenc_df.loc[:, horas].sum(axis=1)\n",
        "\n",
        "    # Consolidar los datos de aenc\n",
        "    consolidated_aenc_df = pd.concat([consolidated_aenc_df, aenc_df], ignore_index=True)\n",
        "\n",
        "    # Unir los dos dataframes utilizando \"CODIGO FRONTERA\"\n",
        "    merged_df = pd.merge(aenc_df, tfroc_df[[\"CODIGO FRONTERA\", \"FACTOR DE PERDIDAS\", \"MERCADO COMERCIALIZACIÓN QUE EXPORTA\", \"NIVEL DE TENSION\"]], on=\"CODIGO FRONTERA\", how=\"inner\")\n",
        "\n",
        "    # Dividir los valores de consumo horario por el FACTOR DE PERDIDAS\n",
        "    for hora in horas:\n",
        "        merged_df[hora] = merged_df[hora] / merged_df[\"FACTOR DE PERDIDAS\"]\n",
        "\n",
        "    # Agregar columnas adicionales al archivo de salida\n",
        "    merged_df.rename(columns={\"CODIGO PROPIO\": \"NOMBRE FRONTERA\"}, inplace=True)\n",
        "    daily_df = merged_df.loc[:, [\"CODIGO FRONTERA\", \"NOMBRE FRONTERA\", \"MERCADO COMERCIALIZACIÓN QUE EXPORTA\", \"NIVEL DE TENSION\",\"TIPO DE AGRUPACIÓN\", \"IMPO - EXPO\"] + horas]\n",
        "\n",
        "    # Agregar columna de fecha, día y tipo de día\n",
        "    daily_df.insert(0, \"FECHA\", date)\n",
        "    daily_df.insert(1, \"DIA\", obtener_dia_semana(date))\n",
        "    daily_df.insert(2, \"TIPO_DIA\", tipo_dia(date))\n",
        "\n",
        "    # Agregar columna \"OR\" basada en el mapeo\n",
        "    daily_df.insert(6, \"OR\", daily_df[\"MERCADO COMERCIALIZACIÓN QUE EXPORTA\"].map(mapeo_or))\n",
        "\n",
        "    # Agregar columna \"NT\" basada en la función de mapeo por rangos\n",
        "    daily_df.insert(8, \"NT\", daily_df[\"NIVEL DE TENSION\"].map(mapear_nt_por_rango))\n",
        "\n",
        "    # Agregar columna de total de consumo por frontera\n",
        "    daily_df[\"TOTAL CONSUMO\"] = daily_df.loc[:, horas].sum(axis=1)\n",
        "\n",
        "    # Agregar los resultados al dataframe consolidado\n",
        "    consolidated_df = pd.concat([consolidated_df, daily_df], ignore_index=True)\n",
        "\n",
        "# Exportar el archivo de aenc consolidado\n",
        "mes_archivos = aenc_files[0][4:6]  # Obtener el mes de los archivos cargados\n",
        "output_aenc_file_name = f\"aenc_consolidado_{mes_archivos}_{anio_actual}.csv\"\n",
        "consolidated_aenc_df.to_csv(output_aenc_file_name, index=False, sep=\";\", encoding='utf-8-sig')\n",
        "files.download(output_aenc_file_name)\n",
        "print(f\"\\nEl archivo {output_aenc_file_name} ha sido descargado\")\n",
        "\n",
        "# Exportar el archivo de consumos consolidado\n",
        "output_file_name = f\"consumos_{mes_archivos}_{anio_actual}.csv\"\n",
        "consolidated_df.to_csv(output_file_name, index=False, sep=\";\", encoding='utf-8-sig')\n",
        "files.download(output_file_name)\n",
        "print(f\"\\nEl archivo {output_file_name} ha sido descargado\")\n",
        "\n",
        "# Generar y exportar el archivo consolidado total de consumo por frontera\n",
        "consolidated_total_df = consolidated_df.groupby([\"CODIGO FRONTERA\", \"NOMBRE FRONTERA\"], as_index=False).agg({\"TOTAL CONSUMO\": \"sum\"})\n",
        "output_total_file_name = f\"total_consumo_{mes_archivos}_{anio_actual}.csv\"\n",
        "consolidated_total_df.to_csv(output_total_file_name, index=False, sep=\";\", encoding='utf-8-sig')\n",
        "files.download(output_total_file_name)\n",
        "print(f\"\\nEl archivo {output_total_file_name} ha sido descargado\")"
      ],
      "metadata": {
        "id": "jyBeGWBJKOb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Borrar la carpeta `content`\n",
        "\n",
        "Ejecuta el siguiente código para borrar rapidamente la carpeta \"content\" y todos sus archivos temporales"
      ],
      "metadata": {
        "id": "0s96LngwlcxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta de la carpeta predeterminada en Google Colab\n",
        "folder_path = '/content'\n",
        "\n",
        "# Eliminar todos los archivos en la carpeta\n",
        "for filename in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        os.remove(file_path)\n",
        "\n",
        "print(\"\\nTodos los archivos cargados han sido eliminados de la carpeta content de Google Colab.\")"
      ],
      "metadata": {
        "id": "C9a1a_f4k4Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conexión al ftp"
      ],
      "metadata": {
        "id": "BJC0AWcedvxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ftplib\n",
        "import ssl\n",
        "\n",
        "# Datos de conexión\n",
        "ftp_server = \"xmftps.xm.com.co\"\n",
        "ftp_port = 210\n",
        "ftp_user = \"ISAMDNT\\\\1098742265\"\n",
        "ftp_password = \"*********\"  # Reemplaza con tu contraseña\n",
        "\n",
        "# Crear una conexión SSL/TLS\n",
        "context = ssl.create_default_context()\n",
        "\n",
        "try:\n",
        "    # Conectar al servidor FTP\n",
        "    print(\"Conectando al servidor FTP...\")\n",
        "    ftp = ftplib.FTP_TLS(context=context)\n",
        "    ftp.connect(ftp_server, ftp_port)\n",
        "    print(\"Conexión establecida.\")\n",
        "\n",
        "    # Iniciar sesión\n",
        "    print(\"Iniciando sesión...\")\n",
        "    ftp.login(ftp_user, ftp_password)\n",
        "    print(\"Sesión iniciada.\")\n",
        "\n",
        "    # Cambiar a modo de protección de datos\n",
        "    ftp.prot_p()\n",
        "    print(\"Modo de protección de datos activado.\")\n",
        "\n",
        "    # Navegar a la ruta específica\n",
        "    ruta = '/INFORMACION_XM/USUARIOSK/RTQC/sic/comercia'\n",
        "    print(f\"Navegando a la ruta: {ruta}\")\n",
        "    ftp.cwd(ruta)\n",
        "    print(\"Navegación exitosa.\")\n",
        "\n",
        "    # Listar archivos en el directorio actual\n",
        "    print(\"Listando archivos en el directorio:\")\n",
        "    ftp.retrlines('LIST')\n",
        "\n",
        "except ftplib.all_errors as e:\n",
        "    print(f\"Error en la conexión FTP: {e}\")\n",
        "\n",
        "finally:\n",
        "    # Cerrar la conexión\n",
        "    ftp.quit()\n",
        "    print(\"Conexión cerrada.\")"
      ],
      "metadata": {
        "id": "4yndTRsRduav"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_WF4iWrT-HqO"
      ],
      "authorship_tag": "ABX9TyP+eyAcxFqR+zmkCV6+eqNV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andresbadillo/aenc_tfroc/blob/master/aenc_tfroc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Consumo = aenc / Factor de p칠rdidas del `-d칤a-`\n",
        "\n",
        "En este pieza se c칩digo se cargan los archivos aenc y tfroc del mismo d칤a seleccionado y se realiza la divisi칩n de cada valor horario por el factor de perdidas"
      ],
      "metadata": {
        "id": "_WF4iWrT-HqO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "to3EiQTEyooS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar los archivos desde Google Colab\n",
        "from google.colab import files\n",
        "\n",
        "# Subir los archivos\n",
        "print(\"Por favor, sube el archivo aenc\")\n",
        "aenc_file = files.upload()\n",
        "\n",
        "print(\"\\nPor favor, sube el archivo tfroc\")\n",
        "tfroc_file = files.upload()\n",
        "\n",
        "# Leer los archivos con el separador \";\"\n",
        "aenc_file_path = list(aenc_file.keys())[0]\n",
        "tfroc_file_path = list(tfroc_file.keys())[0]\n",
        "\n",
        "aenc_df = pd.read_csv(aenc_file_path, sep=\";\", encoding='latin1')\n",
        "tfroc_df = pd.read_csv(tfroc_file_path, sep=\";\", encoding='latin1')\n",
        "\n",
        "# Renombrar columnas para facilitar la uni칩n\n",
        "aenc_df.rename(columns={\"CODIGO SIC\": \"CODIGO FRONTERA\"}, inplace=True)\n",
        "\n",
        "# Unir los dos dataframes utilizando \"CODIGO FRONTERA\"\n",
        "merged_df = pd.merge(aenc_df, tfroc_df[[\"CODIGO FRONTERA\", \"FACTOR DE PERDIDAS\"]], on=\"CODIGO FRONTERA\", how=\"inner\")\n",
        "\n",
        "# Dividir los valores de aenc horario por el FACTOR DE PERDIDAS\n",
        "horas = [col for col in aenc_df.columns if \"HORA\" in col]\n",
        "for hora in horas:\n",
        "    merged_df[hora] = merged_df[hora] / merged_df[\"FACTOR DE PERDIDAS\"]\n",
        "\n",
        "# Agregar columnas adicionales al archivo de salida\n",
        "merged_df.rename(columns={\"CODIGO PROPIO\": \"NOMBRE FRONTERA\"}, inplace=True)\n",
        "output_df = merged_df[[\"CODIGO FRONTERA\", \"NOMBRE FRONTERA\", \"TIPO DE AGRUPACI칍N\", \"IMPO - EXPO\"] + horas]\n",
        "\n",
        "# Agregar columna de total de consumo por frontera\n",
        "output_df[\"TOTAL CONSUMO\"] = output_df[horas].sum(axis=1)\n",
        "\n",
        "# Exportar a un archivo CSV\n",
        "output_file_name = \"consumos_1201.csv\"\n",
        "output_df.to_csv(output_file_name, index=False, sep=\";\")\n",
        "\n",
        "# Descargar el archivo resultante\n",
        "files.download(output_file_name)\n",
        "print(f\"\\nEl archivo {output_file_name} ha sido descargado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Consumo = aenc / Factor de p칠rdidas del `-Mes-`\n",
        "\n",
        "En este pieza se c칩digo se cargan los archivos aenc y tfroc del mismo mes y se realiza la divisi칩n de cada valor horario por el factor de perdidas. Hay dos archivos exportados:\n",
        "- Archivo que consolida todos los aenc del mes: aenc_consolidado_`{mm}`_`{aaaa}`.csv\n",
        "- Archivo que consolida los consumos del mes: consumos_`{mm}`_`{aaaa}`.csv"
      ],
      "metadata": {
        "id": "_USsogaE-1yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install holidays_co\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "import holidays_co\n",
        "\n",
        "# Configurar el a침o\n",
        "anio_actual = 2025  # Cambiar este valor seg칰n sea necesario\n",
        "\n",
        "# Cargar los archivos desde Google Colab\n",
        "from google.colab import files\n",
        "\n",
        "# Subir los archivos\n",
        "aenc_files = []\n",
        "tfroc_files = []\n",
        "\n",
        "print(\"Por favor, sube todos los archivos de 'aenc' del mes\")\n",
        "aenc_uploaded = files.upload()\n",
        "aenc_files.extend(aenc_uploaded.keys())\n",
        "\n",
        "print(\"\\nPor favor, sube todos los archivos de 'tfroc' del mes\")\n",
        "tfroc_uploaded = files.upload()\n",
        "tfroc_files.extend(tfroc_uploaded.keys())\n",
        "\n",
        "# Inicializar dataframes vac칤os para consolidar los resultados\n",
        "consolidated_aenc_df = pd.DataFrame()\n",
        "consolidated_df = pd.DataFrame()\n",
        "\n",
        "# Funci칩n para obtener el nombre del d칤a en espa침ol\n",
        "def obtener_dia_semana(fecha):\n",
        "    dias_semana = [\"Lunes\", \"Martes\", \"Mi칠rcoles\", \"Jueves\", \"Viernes\", \"S치bado\", \"Domingo\"]\n",
        "    dia_semana = datetime.strptime(fecha, \"%d-%m-%Y\").weekday()\n",
        "    return dias_semana[dia_semana]\n",
        "\n",
        "# Obtener los festivos de Colombia para el a침o configurado\n",
        "festivos = holidays_co.get_colombia_holidays_by_year(anio_actual)\n",
        "#print(f\"Festivos del a침o {anio_actual}: {festivos}\")\n",
        "\n",
        "# Funci칩n para determinar el tipo de d칤a\n",
        "def tipo_dia(fecha):\n",
        "    fecha_obj = datetime.strptime(fecha, \"%d-%m-%Y\").date()\n",
        "\n",
        "    if holidays_co.is_holiday_date(fecha_obj):  # Verificar si es festivo\n",
        "        return \"Festivo\"\n",
        "\n",
        "    # Si no es festivo, determinar si es lunes a viernes, s치bado o domingo\n",
        "    dia_semana = fecha_obj.weekday()  # 0: Lunes, 1: Martes, ..., 6: Domingo\n",
        "    if dia_semana == 5:  # S치bado\n",
        "        return \"S치bado\"\n",
        "    elif dia_semana == 6:  # Domingo\n",
        "        return \"Domingo\"\n",
        "    else:  # Lunes a Viernes\n",
        "        return \"H치bil\"\n",
        "\n",
        "# Diccionario de mapeo para la columna \"OR\"\n",
        "mapeo_or = {\n",
        "    \"CUNM\": \"ENEL\",\n",
        "    \"SOLM\": \"AIRE\",\n",
        "    \"SANM\": \"ESSA\",\n",
        "    \"MARM\": \"AFINIA\",\n",
        "    \"NSAM\": \"ESSA\",\n",
        "    \"BOYM\": \"EBSA\",\n",
        "    \"CASM\": \"ENERCA\",\n",
        "    \"METM\": \"EMSA\",\n",
        "    \"QUIM\": \"EDEQ\",\n",
        "    \"RUIM\": \"RUITOQUE\",\n",
        "    \"CHOM\": \"DISPAC\",\n",
        "    \"CLOM\": \"EMCALI\"\n",
        "}\n",
        "\n",
        "# Funci칩n para mapear el NT por rangos\n",
        "def mapear_nt_por_rango(valor):\n",
        "    if valor in {1, 2}:  # Comprobamos si el valor es exactamente 1 o 2\n",
        "        return valor\n",
        "    elif valor < 1:\n",
        "        return 1\n",
        "    elif valor < 30:\n",
        "        return 2\n",
        "    elif valor < 57.5:\n",
        "        return 3\n",
        "    return None  # O un valor por defecto si no encaja en ning칰n rango\n",
        "\n",
        "# Procesar archivos d칤a a d칤a\n",
        "for aenc_file_path in aenc_files:\n",
        "    # Extraer el d칤a y el mes del nombre del archivo\n",
        "    day = os.path.splitext(aenc_file_path)[0][-4:]  # Los 칰ltimos 4 caracteres son el d칤a\n",
        "    date = f\"{day[2:]}-{day[:2]}-{anio_actual}\"  # Formatear como dd-mm-aaaa\n",
        "\n",
        "    # Buscar el archivo tfroc correspondiente\n",
        "    tfroc_file_path = next((f for f in tfroc_files if day in f), None)\n",
        "    if tfroc_file_path is None:\n",
        "        print(f\"No se encontr칩 un archivo tfroc correspondiente para el d칤a {day}.\")\n",
        "        continue\n",
        "\n",
        "    # Leer los archivos con el separador \";\"\n",
        "    aenc_df = pd.read_csv(aenc_file_path, sep=\";\", encoding='latin1')\n",
        "    tfroc_df = pd.read_csv(tfroc_file_path, sep=\";\", encoding='latin1')\n",
        "\n",
        "    # Renombrar columnas para facilitar la uni칩n\n",
        "    aenc_df.rename(columns={\"CODIGO SIC\": \"CODIGO FRONTERA\"}, inplace=True)\n",
        "\n",
        "    # Agregar columnas adicionales al dataframe de aenc\n",
        "    horas = [col for col in aenc_df.columns if \"HORA\" in col]\n",
        "    aenc_df.insert(0, \"FECHA\", date)\n",
        "    aenc_df.insert(1, \"DIA\", obtener_dia_semana(date))\n",
        "    aenc_df.insert(2, \"TIPO_DIA\", tipo_dia(date))\n",
        "    aenc_df[\"TOTAL CONSUMO\"] = aenc_df.loc[:, horas].sum(axis=1)\n",
        "\n",
        "    # Consolidar los datos de aenc\n",
        "    consolidated_aenc_df = pd.concat([consolidated_aenc_df, aenc_df], ignore_index=True)\n",
        "\n",
        "    # Unir los dos dataframes utilizando \"CODIGO FRONTERA\"\n",
        "    merged_df = pd.merge(aenc_df, tfroc_df[[\"CODIGO FRONTERA\", \"FACTOR DE PERDIDAS\", \"MERCADO COMERCIALIZACI칍N QUE EXPORTA\", \"NIVEL DE TENSION\"]], on=\"CODIGO FRONTERA\", how=\"inner\")\n",
        "\n",
        "    # Dividir los valores de consumo horario por el FACTOR DE PERDIDAS\n",
        "    for hora in horas:\n",
        "        merged_df[hora] = merged_df[hora] / merged_df[\"FACTOR DE PERDIDAS\"]\n",
        "\n",
        "    # Agregar columnas adicionales al archivo de salida\n",
        "    merged_df.rename(columns={\"CODIGO PROPIO\": \"NOMBRE FRONTERA\"}, inplace=True)\n",
        "    daily_df = merged_df.loc[:, [\"CODIGO FRONTERA\", \"NOMBRE FRONTERA\", \"MERCADO COMERCIALIZACI칍N QUE EXPORTA\", \"NIVEL DE TENSION\",\"TIPO DE AGRUPACI칍N\", \"IMPO - EXPO\"] + horas]\n",
        "\n",
        "    # Agregar columna de fecha, d칤a y tipo de d칤a\n",
        "    daily_df.insert(0, \"FECHA\", date)\n",
        "    daily_df.insert(1, \"DIA\", obtener_dia_semana(date))\n",
        "    daily_df.insert(2, \"TIPO_DIA\", tipo_dia(date))\n",
        "\n",
        "    # Agregar columna \"OR\" basada en el mapeo\n",
        "    daily_df.insert(6, \"OR\", daily_df[\"MERCADO COMERCIALIZACI칍N QUE EXPORTA\"].map(mapeo_or))\n",
        "\n",
        "    # Agregar columna \"NT\" basada en la funci칩n de mapeo por rangos\n",
        "    daily_df.insert(8, \"NT\", daily_df[\"NIVEL DE TENSION\"].map(mapear_nt_por_rango))\n",
        "\n",
        "    # Agregar columna de total de consumo por frontera\n",
        "    daily_df[\"TOTAL CONSUMO\"] = daily_df.loc[:, horas].sum(axis=1)\n",
        "\n",
        "    # Agregar los resultados al dataframe consolidado\n",
        "    consolidated_df = pd.concat([consolidated_df, daily_df], ignore_index=True)\n",
        "\n",
        "# Exportar el archivo de aenc consolidado\n",
        "mes_archivos = aenc_files[0][4:6]  # Obtener el mes de los archivos cargados\n",
        "output_aenc_file_name = f\"aenc_consolidado_{mes_archivos}_{anio_actual}.csv\"\n",
        "consolidated_aenc_df.to_csv(output_aenc_file_name, index=False, sep=\";\", encoding='utf-8-sig')\n",
        "files.download(output_aenc_file_name)\n",
        "print(f\"\\nEl archivo {output_aenc_file_name} ha sido descargado\")\n",
        "\n",
        "# Exportar el archivo de consumos consolidado\n",
        "output_file_name = f\"consumos_{mes_archivos}_{anio_actual}.csv\"\n",
        "consolidated_df.to_csv(output_file_name, index=False, sep=\";\", encoding='utf-8-sig')\n",
        "files.download(output_file_name)\n",
        "print(f\"\\nEl archivo {output_file_name} ha sido descargado\")\n",
        "\n",
        "# Generar y exportar el archivo consolidado total de consumo por frontera\n",
        "consolidated_total_df = consolidated_df.groupby([\"CODIGO FRONTERA\", \"NOMBRE FRONTERA\",\"TIPO DE AGRUPACI칍N\", \"IMPO - EXPO\"], as_index=False).agg({\"TOTAL CONSUMO\": \"sum\"})\n",
        "output_total_file_name = f\"total_consumo_{mes_archivos}_{anio_actual}.csv\"\n",
        "consolidated_total_df.to_csv(output_total_file_name, index=False, sep=\";\", encoding='utf-8-sig')\n",
        "files.download(output_total_file_name)\n",
        "print(f\"\\nEl archivo {output_total_file_name} ha sido descargado\")"
      ],
      "metadata": {
        "id": "jyBeGWBJKOb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Borrar la carpeta `content`\n",
        "\n",
        "Ejecuta el siguiente c칩digo para borrar rapidamente la carpeta \"content\" y todos sus archivos temporales"
      ],
      "metadata": {
        "id": "0s96LngwlcxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta de la carpeta predeterminada en Google Colab\n",
        "folder_path = '/content'\n",
        "\n",
        "# Eliminar todos los archivos en la carpeta\n",
        "for filename in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        os.remove(file_path)\n",
        "\n",
        "print(\"\\nTodos los archivos cargados han sido eliminados de la carpeta content de Google Colab.\")"
      ],
      "metadata": {
        "id": "C9a1a_f4k4Dq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a07abde1-5e3a-418c-960e-0ea937570d16"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Todos los archivos cargados han sido eliminados de la carpeta content de Google Colab.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conexi칩n al ftp"
      ],
      "metadata": {
        "id": "BJC0AWcedvxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shareplum # Ejecutar en una celda aparte\n",
        "!pip show shareplum # Ejecutar en una celda aparte\n",
        "\n",
        "from ftplib import FTP_TLS\n",
        "from shareplum import Site\n",
        "from shareplum import Office365\n",
        "from shareplum.site import Version\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# 游댳 DATOS DE CONEXI칍N FTP\n",
        "ftp_server = \"xmftps.xm.com.co\"\n",
        "ftp_port = 210\n",
        "ftp_user = \"ISAMDNT\\\\1098742265\"\n",
        "ftp_password = \"Ru1t0qu309p2025*\"\n",
        "\n",
        "# 游댳 DATOS DE SHAREPOINT\n",
        "sharepoint_url = \"https://ruitoqueesp1.sharepoint.com\"\n",
        "sharepoint_site = \"fronterascomerciales\"  # Nombre del sitio en SharePoint\n",
        "sharepoint_user = \"rbadillo@ruitoqueesp.com\"\n",
        "sharepoint_password = \"r2083502R\"\n",
        "\n",
        "# 游댳 VARIABLES PARA A칌O Y MES (MODIFICABLES)\n",
        "anio_especifico = None  # Cambia esto si quieres un a침o espec칤fico (ej: 2023)\n",
        "mes_especifico = None   # Cambia esto si quieres un mes espec칤fico (ej: 02 para febrero)\n",
        "\n",
        "# 游댳 OBTENER A칌O Y MES SEG칔N CONFIGURACI칍N\n",
        "anio_actual = anio_especifico if anio_especifico else datetime.now().year\n",
        "numero_mes = f\"{mes_especifico:02d}\" if mes_especifico else datetime.now().strftime(\"%m\")\n",
        "ruta_ftp = f\"/INFORMACION_XM/USUARIOSK/RTQC/sic/comercia/{anio_actual}-{numero_mes}\"\n",
        "\n",
        "# 游댳 DEFINIR FOLDER DESTINO DE SHAREPOINT\n",
        "sharepoint_folder = f\"Documentos Compartidos/aenc/{anio_actual}/{numero_mes}\"\n",
        "\n",
        "# 游댳 CONECTARSE A FTP\n",
        "try:\n",
        "    print(\"Conectando al servidor FTP...\")\n",
        "    connection = FTP_TLS()\n",
        "    connection.connect(ftp_server, ftp_port)\n",
        "    connection.login(user=ftp_user, passwd=ftp_password)\n",
        "    connection.set_pasv(True)\n",
        "    connection.prot_p()\n",
        "    print(\"Conexi칩n establecida.\")\n",
        "\n",
        "    # Navegar a la carpeta en el FTP\n",
        "    connection.cwd(ruta_ftp)\n",
        "    print(f\"Navegando a la ruta FTP: {ruta_ftp}\")\n",
        "\n",
        "    # Listar archivos y filtrar los que comienzan con \"aenc\" o \"tfroc\"\n",
        "    archivos_ftp = connection.nlst()\n",
        "    archivos_descargar = [archivo for archivo in archivos_ftp if archivo.startswith((\"aenc\", \"tfroc\"))]\n",
        "\n",
        "    if not archivos_descargar:\n",
        "        print(\"No se encontraron archivos para descargar.\")\n",
        "    else:\n",
        "        print(f\"Archivos a descargar: {archivos_descargar}\")\n",
        "\n",
        "        # Crear carpeta temporal para almacenar archivos descargados\n",
        "        temp_folder = \"archivos_descargados\"\n",
        "        os.makedirs(temp_folder, exist_ok=True)\n",
        "\n",
        "        for archivo in archivos_descargar:\n",
        "            local_path = os.path.join(temp_folder, archivo)\n",
        "            with open(local_path, \"wb\") as f:\n",
        "                connection.retrbinary(f\"RETR {archivo}\", f.write)\n",
        "            print(f\"Archivo descargado: {archivo}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error en la conexi칩n FTP: {e}\")\n",
        "\n",
        "finally:\n",
        "    if 'connection' in locals():\n",
        "        connection.quit()\n",
        "        print(\"Conexi칩n FTP cerrada.\")\n",
        "\n",
        "# 游댳 CONECTARSE A SHAREPOINT Y SUBIR ARCHIVOS\n",
        "try:\n",
        "    print(\"Conectando a SharePoint...\")\n",
        "    authcookie = Office365(sharepoint_url, username=sharepoint_user, password=sharepoint_password).GetCookies()\n",
        "    site = Site(f\"{sharepoint_url}/sites/{sharepoint_site}\", authcookie=authcookie, version=Version.v365)\n",
        "    folder = site.Folder(sharepoint_folder)\n",
        "    print(\"Conexi칩n a SharePoint establecida.\")\n",
        "\n",
        "    # Subir los archivos al SharePoint\n",
        "    for archivo in archivos_descargar:\n",
        "        local_path = os.path.join(temp_folder, archivo)\n",
        "        with open(local_path, \"rb\") as file:\n",
        "            file_content = file.read()\n",
        "            folder.upload_file(file_content, archivo)\n",
        "            print(f\"Archivo subido a SharePoint: {archivo}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error en la conexi칩n a SharePoint: {e}\")"
      ],
      "metadata": {
        "id": "wSWtih9l7r3V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}